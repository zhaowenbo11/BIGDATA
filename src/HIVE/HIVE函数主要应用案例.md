# HIVE函数主要应用案例

## hive中多字节分隔符处理

#### 默认规则
- hive默认序列化类是LazySimpleSerDe，其只支持单字节分隔符（char）

#### 解决方案一：替换分隔符
- 使用MR程序提前将数据中的多字节分隔符替换为单字节分隔符

#### 解决方案二：RegexSerDe正则加载（推荐）
- RegexSerDe用来加载特殊数据的问题，使用正则匹配

### 解决方案三：自定义InputFormat（较为复杂，不推荐）
- hive中也允许使用自定义InputFormat来解决问题，通过在自定义InputFormat，来自定义
- 与MR中自定义的RecordReader一致，实现RecordReader接口，实现next方法

## URL解析函数

#### 实际工作需求
- 分析需求：业务需求中，经常需要对用户的访问、用户的来源进行分析，用于支持运营和决策
####  URL的基本组成：协议类型+域名（host）+访问路径（path）+参数数据（query）
#### hive对URL的解析
- parse_url和parse_url_tuple函数
#### parse_url函数
- 功能：是hive中提供的最基本的url解析函数，可以根据指定的参数，从url解析出对于的参数值进行返回，函数为UDF类型
- 语法：
- 如果想一次解析多个参数，需要使用多次函数

#### parse_url_tuple函数
- 功能：是UDTF函数类型，输入一行，输出多行，这里是特殊情况，select时不能包含其他字段、不能嵌套调用、不能与group by等放在一起调用等等
- UDTF函数的调用方式：1，直接在select后单独使用；2，与Lateral View（侧视图）放在一起使用

#### Lateral View（侧视图）
- 主要用于搭配UDTF类型功能的函数一起使用，用于解决UDTF函数的一些查询限制的问题
- 语法：select ... from tableA lateral view UDTF(xxx) 别名 as col1,col2,...
- 如果UDTF不产生数据时，这时侧视图与原表关联的结果将为空
- 如果加上outer关键字以后，就会保留原表数据，类似于outer join

## 行列转换应用与实现

#### 实际需求
- 统计得到每个小时的UV、PV、IP的个数，但是表中的数据存储格式不利于直接查询展示，需要进行调整

#### 行转列：多行转多列
- **case when 函数**
- 语法一： CASE
- 		WHEN 条件1 THEN VALUE1
- 		WHEN 条件N THEN VALUEN
- 		ELSE 默认值 END

- 语法二：CASE 列
- 		WHEN V1 THEN VALUE1
- 		WHEN VN  THEN VALUEN
- 		ELSE 默认值 END

#### 行转列：多行转单列
- **concat函数**
- 功能：用于实现字符串拼接，不可指定分隔符
- 语法：concat（element1,element2,element3,...)
- 特点：如果任意一个元素为NULL,结果就为NULL
- **concat_ws函数**
- 功能：用于实现字符串拼接，可以指定分隔符，仅支持string | array（string）
- 语法：concat_ws("-","itcast","and","heima")
- **collect_list函数**
- 功能：用于将一列中的多行合并为一列，不进行去重
- 语法：collect_list(colName)
- **collect_set函数**
- 功能：用于将一列中的多行合并为一行，进行去重
- 语法：collect_set(colName)

#### 列转行：多列转多行
- **union关键字**
- 功能：将多个select语句结果合并为一个，且结果去重并排序
- **union all 关键字**
- 功能：将多个select语句结果合并为一个，且结果不去重不排序

#### 列转行：单列转多行（重要）
- **explode函数**
- 功能：用于将一个集合或数组中的每个元素展开，将每个元素变成一行
- 语法：explode（Map | Array）

## JSON数据处理
#### JSON格式
- 是最常见的结构化数据格式之一

#### 方式一：使用JSON函数处理
- get_json_object、json_tuple这两个函数都可以实现将JSON数据中的每个字段独立解析处理，构建成表
- **get_json_objet**
- 功能：用于解析JSON字符串，可以从JSON字符串中返回指定的某个对象列的值
- 语法：get_json_object(json_txt,path) 
- 参数：1，指定要解析的JSON字符串；2，指定要返回的字段，通过$.columnName的方式来指定path
- 特点：每次只能返回JSON对象中一列的值
- **json_tuple**
- 功能：用于解析JSON字符串，可以通过指定多个参数来解析JSON返回多列的值
- 语法：json_tuple(jsonStr,p1,p2,...,pn)
- 参数：1，指定要解析的JSON字符串；2，指定要返回的第一个字段；3，指定要返回的第n个字段
- 特点：属于UDTF类型函数，一般搭配lateral view使用；返回的每一列都是字符串类型

#### 方式二：JSON SerDe加载数据
- 建表时指定SerDe，加载JSON文件到表中，会自动解析为对应的表格式

## 窗口函数应用实例

### 案例1：连续登陆用户
#### 需求：统计连续N次登录的用户（N>=2)
#### 实现方案分析：想要得到连续登录用户，必须找到两个

#### 窗口函数实现
- lead
- 功能：用于从当前数据中居于当前行的数据向后偏移取值
- 语法：lead(colName,N,defautValue)
- colName：取哪一列的值

### 案例2：级联累加求和
#### 需求：统计每个用户每个月的消费总金额以及当前累计消费总金额
#### 实现方案分析：
- 首先要统计出每个用户每个月的消费总金额，分组实现聚合，但是需要按照用户ID，将该用户这个月之前的所有月份的消费总金额进行累加实现

#### 方案：分组统计每个用户每个月的消费金额，然后使用窗口聚合函数实现
- 窗口函数sum
- 功能：用于实现基于窗口的数据求和
- 语法：sum(colName) over (partition by col order by col)
- colName：对某一列的值进行求和

### 案例3：分组TopN
#### 需求：统计查询每个部门薪资最高的前两名员工的薪水
#### 实现方案分析：使用窗口函数的排列函数
- 窗口排列函数



## 拉链表的设计与实现

### 背景：数据同步问题
- hive在实际工作中主要作用于构建离线数据仓库，定期从各种数据源中同步采集数据到hive中，经过分层转换提供数据应用
### 解决方案一：直接更新
- 优点：实现简单
- 缺点：没有历史状态

### 解决方案二：每次数据改变，根据日期构建一份全量的快照表，每天一张表
- 优点：记录了所有数据在不同时间的状态
- 缺点：冗余存储了很多没有发生变化的数据，导致存储的数据量过大

### 解决方案三：构建拉链表，通过时间标记发生变化的数据的每种状态的时间周期

### 功能与应用场景
- 拉链表专门用于解决在数据仓库中数据发生变化如何实现数据存储的问题
- 拉链表的设计是将更新的数据进行状态记录，没有发生更新的数据不进行状态存储，用于存储所有数据在不同时间上的所有状态，通过时间进行标记每个状态的生命周期，查询时，根据需求可以获取指定时间范围状态的数据，默认用9999-12-31等最大值来表示最新状态。

### 实现过程
1. 增量采集最新的数据
2. hive ODS层增量表和DW层的拉链表进行union all 为TMP层的临时表
3. 保存为新的拉链表