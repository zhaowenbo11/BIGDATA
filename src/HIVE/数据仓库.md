# 数据仓库

## 概念
- **数据仓库**（Data Warehouse，简称数仓、DW），是一个用于存储、分析、报告的数据系统
- 数据仓库的目的是构建**面向分析**的集成化数据环境，分析结果为企业提供决策支持（Decision Support)
- **特点**：
1. 数据仓库本身不生产如何数据，其数据来源于不同外部系统
2. 同时数仓自身也不需要消费如何的数据，其结果开放给各个部分使用.

## 数据仓库为何而来
1. **操作型记录的保存**
- 关系型数据库（RDBMS)是OLTP典型应用，如：Oracle、Mysql、SQL、Server等
2. **分析型决策的制定**
- 基于业务数据展开数据分析，基于分析的结果给决策提供支撑。也就是所谓的***数据驱动决策***的制定。

#### OLTP环境开展分析可行吗？
可以，但没有必要
- OLTP所有业务分为读和写两种操作

#### 数据仓库的构建
- 如数仓定义所说，数仓是一个用于存储、分析、报告的数据系统，目的是构建面向分析的集成化数据环境。我们把**这种面向分析、支持分析的系统称之为OLAP(联机分析处理)系统**。数据仓库是OLAP一种。

## 主要特征
1. **面向主题性（Subject-Oriented)**：主题是一个抽象的概念，是较高层次上数据综合、归类并进行分析利用的抽象。
2. **集成性（Integrated）**：主题相关的数据通常会分布在多个操作型系统中，彼此分散、独立、异构。需要集成到数仓主题下。
- 确定主题后，就需要获取和主题相关的数据。当下企业中主题相关的数据通常会分布在多个操作型系统中，彼此分散、独立、异构
- 因此在数据进入数据仓库前，必然要经过统一与综合，对数据进行抽取、清理、转换和汇总，这一步是数据仓库建设中最关键、最复杂的一步。
3. **非易失性（Non-Volatile）**：也叫非易变性。数据仓库是分析数据的平台，而不是创造数据的平台。
4. **时变性**：数据仓库的数据需要随着时间的更新，以适应决策的需要。

# OLTP、OLAP

## 概念
- OLTP(On-line Transaction Processing)：操作型处理，叫做联机事务处理，主要目标是做数据处理，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。也可以理解为RDBMS
- OLAP(On-line Analytical Processing)：分析型处理，叫做联机分析处理，主要目标是做数据分析。
![](F:\大数据开发\Hive3.x\1.jpg)

# 数据仓库、数据库

## 区别
- 实际上是OLTP和OLAP的区别
- OLTP的典型应用就是RDBMS,NoSQL不在本范围内
- 数据仓库不是大型的数据库，虽然数据仓库存储数据规模大
- 数据仓库的出现并不是要取代数据库
- 数据库是面向事务的设计，数据仓库是面向主题设计的
- 数据库一般存储业务数据，数据仓库存储的一般是历史数据
- **数据库是为捕获数据而设计，数据仓库是为分析数据而设计**

# 数据仓库、数据集市

## 区别
- 数据仓库(Data Warehouse)是面向整个集团组织的数据，数据集市(Data Mart)是面向单个部门使用的
- 数据集市也可以叫做小型的数据仓库

# 数据仓库分层架构

## 分层思想和标准
- 数据仓库的特点是本身不生产数据，也不最终消费数据。按照数据流入流出数仓的过程进行分层就显得水到渠成。
- 每个企业根据自己的业务需求可以分成不同的层次。但是最基础的分层思想，理论上分为三层：操作型数据层（ODS）、数据仓库层（DW）、数据应用层（DA）
- 企业在实际运用中可以基于这个基础分层之上添加新的层次，来满足不同的业务需求

## 阿里巴巴数仓3层架构

#### ODS层
- 操作型数据层，也称之为源数据层、数据引入层、数据暂存层、临时缓存层
- 此层存放未经过处理的原始数据至数据仓库系统，结构上与源系统保持一致，是数据仓库的数据准备区。
#### DW层
- 数据仓库层，由ODS层数据经过ETL处理加工而成。主要完成数据加工与整合，建立一致的维度
#### DA层（或ADS层）
- 数据应用层，面向最终用户，面向业务定制提供给产品和数据分析使用的数据
- 包括前端报表、分析图表、KPI、仪表盘、数据挖掘等分析

## 分层的好处
1. 清晰数据结构
- 每一个数据分层都有它的作用域，在使用表的时候能更方便地定位和理解
2. 数据血缘追踪
- 简单来说，我们最终给业务呈现的是一个能直接使用的业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围
3. 减少重复开发
- 规范数据分层，开发一些通用的中间层数据，能够减少极大的运算
4. 把复杂问题简单化
5. 屏蔽原始数据的异常

# ETL、ELT

抽取Extra、转化Transfer、加载Load
## 背景
- 数据仓库从各数据源获取数据及在数据仓库内的数据转换和流动都可以认为是ETL的过程
- 但是在实际操作中将数据加载到仓库却产生了两种不同做法：ETL和ELT

## ETL
- 首先从数据源池中提取数据，这些数据源通常是事务性数据库。数据保存在临时暂存数据库中（OBS），然后执行转换操作，将数据结构化并转换为适合目标数据仓库系统的形式。然后将结构化数据加载到仓库中，以备分析

## ELT
- 使用ELT，数据在从源数据池中提取后立即加载。没有专门的临时数据库（ODS），这意味着数据会立即加载到单一的集中存储库中。数据在数据仓库系统中进行转换，以便与商业智能工具（BI工具）一起使用。**大数据时代的数仓这个特点很明显**

# Apache Hive概述
## 什么是Hive
- Apache Hive是一款建立在Hadoop之上的开源数据仓库系统，**可以将存储在Hadoop文件中的结构化、半结构化数据文件映射为一张数据库表**，基于表提供了一种类似SQL的查询模型，称为Hive查询语言（HQL）用于访问和分析存储在Hadoop文件中的大型数据集
- Hive的核心是将HQL转换为MapReduce程序，然后将程序提交到Hadoop集群执行
- Hive由Facebook实现并开源

## 为什么使用Hive
- 使用Hadoop mapreduce直接处理数据所面临的问题：
1. 需要掌握Java语言
2. MapReduce实现复杂查询逻辑开发难度太大
- 使用Hive处理数据的好处
1. 操作接口采用类SQL语法，提供快速开发能力
2. 背靠Hadoop，擅长存储分析海量数据集

## Hive和Hadoop的关系
- 从功能来说，数据仓库软件至少需要具备以下两种能力：存储数据的能力，分析数据的能力
- Hive利用HDFS存储数据，利用MapReduce查询分析数据
- Hive的最大魅力在于**用户专注于编写HQL，Hive帮助用户转换成为MapReduce程序完成对数据的分析**

# Apache Hive架构、组件

i[](F:\大数据开发\Hive3.x\Hive架构图.png)

## 组件
- **用户接口**
包括CLI、JDBC/ODBC、WedGUI.其中，CLI（command line interface）为sehll命令行；Hive中的Thrift服务器允许外部客户端通过网络与Hive进行交互，类似于JDBC或ODBC协议。WebGUI是通过浏览器访问Hive。
- **元数据存储**
通常是存储在关系型数据库中，如MySQL/derby中。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。
- **Driver驱动程序，包括语法解析器、计划编译器、优化器、执行器**
完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后有执行引擎调用执行。
- **执行引擎**
Hive本身并不直接处理数据文件。而是通过执行引擎处理。当下Hive支持MR、Tez、Spark3等


# Apache Hive数据模型

## Data Model概念
- 数据模型：用来描述数据、组织数据和对数据进行操作，是对现实世界数据特征的描述
- Hive的数据模型类似于RDBMS库表结构，此外还有自己特有模型
- Hive中的数据可以在粒度级别上分为三类：Table表、Partition分区、Bucket 分桶

## Databases数据库
- Hive作为一个数据仓库，在结构上积极向传统数据库看齐，也分数据库（Schema），每个数据库下面有各自的表组成。**默认数据库default**
- HIve的数据都是**存储在HDFS上的**，默认有一个根目录，在hive-site.xml中，由参数hive.metastore.warehouse.dir指定。默认值为/user/hive/warehouse
- 因此，Hive中的数据库在HDFS上的存储路径为：hive.metastore.warehouse.dir}databasename.db

## Table表
- Hive表与关系数据库中的表相同。Hive中的表所对应的数据通常是存储在HDFS中，而表相关的元数据是存储在RDBMS中。
- Hive中的表的数据在HDFS上的存储路径为：${hive.metastore.warehouse.dir}/databasename.db/tablename

## Partition分区
- Partition分区是hive的一种优化手段表。分区是指**根据分区列（例如“日期day”）的值将表划分为不同的分区**。这样可以更快地对指定分区数据进行查询
- 分区在存储层面上的表现是：table表目录下以子文件夹形式存在
- 一个文件夹显示一个分区。子文件命名标准：分区列=分区值
- Hive还支持分区下继续创建分区，所谓的多重分区

## Buckets 分桶
- Bucket分桶表是hive的一种优化手段表。分桶是指**根据表中字段(例如“编号ID”)的值，经过hash计算规则将数据文件划分成指定的若干个小文件**
- 分桶规则：hashfunc（字段）%桶个数，余数相同的分到同一个文件
- 分桶的好处是可以**优化join查询和方便抽样查询**
- Bucket分桶表是在HDFS中表现为**同一个表目录下数据根据hash散列之后变成多个文件**

# Hive和MySQL对比
i[](F:\大数据开发\Hive3.x\3.jpg)

# Apache Hive元数据

- 元数据（Metadata），又称中介数据、中继数据，为**描述数据的数据**（data about data),主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能

## Hive Metadata
- Hive Metadata即Hive的元数据
- 包含用Hive创建的database、table、表的位置、类型、属性，字段顺序类型等元信息
- **元数据存储在关系型数据库中**。如hive内置的Derby、或者第三方如MySQL等

## Hive Metastore
- Metastore即**元数据服务**。Metastore服务的作用是**管理metadata元数据**，对外暴露服务地址，让各种客户端通过连接metastore服务，由meta store再去连接MySQL数据库来存取元数据
- 有了meta store服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接meta store服务即可。某种程度上也保证了hive元数据的安全。

# Metastore配置方式
## 概述
- meta store服务配置有3种模式：内嵌模式、本地模式、远程模式
|     | 内嵌模式  | 本地模式 | 远程模式 |
| :---  | ---:  | :--: | ---- |
| Metastore单独配置、启动  | 否 |否|是|
| Metastore存储介质  | Derby |Mysql|Mysql|

## 内嵌模式
- 是meta store默认部署方式
- 此种模式下，元数据存储在内置的Derby数据库，并且Derby数据库和meta store服务都嵌入在主HiveServer进程中，当启动HiveServer进程时，Derby和meta store都会启动。**不需要额外起Metastore服务。**
- 但是一次只能支持一个活动用户，适用于测试体验，不适用于生产环境

## 本地模式
- **本地模式下，meta store服务与主HiveServer进程在同一进程中运行**，但是存储元数据的数据库在单独的进程中运行，并且可以在单独的主机上。meta store服务将通过JDBC与meta store数据库进行通信。
- **本地模式采用外部数据库来存储元数据**，推荐使用MySQL
- hive根据hive.metastore.uris参数值来判断，如果为空，则为本地模式
- 缺点：每启动一次hive服务，都内置启动看一个meta store

## 远程模式
- 远程模式下，Metastore服务在其自己的单独JVM上运行，而不在HiveServer
- 在生产环境中，建议用远程模式来配置Hive Metastore。在这种情况下，其他依赖hive的软件都可以通过meta store访问hive。由于还可以完全屏蔽数据库层，因此这也带来了更好的可管理性/安全性